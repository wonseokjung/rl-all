{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "안녕하세요? 정원석 입니다.\n",
        "\n",
        "여러분, 인터넷에는 많은 이미지들이 있죠. 이번에 제가 만든 인공지능 모델은 이러한 이미지들을 보고 그것들이 무엇인지 예측할 수 있어요. 이 모델은 'Vision Transformer'라는 기술을 사용하는데, 이 기술은 이미지를 분석하고 이해하는 데 정말 뛰어나답니다.\n",
        "\n",
        "저는 인터넷에서 이미지의 URL을 가져와서, '허깅페이스'라는 곳에서 제공하는 Vision Transformer 모델을 이용해요. 그리고 그 이미지가 무엇을 나타내는지 예측하죠. 예를 들면, 사진에 나온 것이 고양이인지, 강아지인지, 아니면 다른 무언가인지 말이에요.Hugging Face의 Transformers 라이브러리를 사용하여 Vision Transformer (ViT) 모델을 테스트하는 방법은 비교적 간단합니다.\n",
        "\n",
        "기본적인 단계는 다음과 같습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "T_Cd8xUhm7eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uvzUBCT4mzKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Hugging Face 라이브러리 설치**:\n",
        "\n",
        "우선, 우리가 필요한 도구인 transformers 라이브러리를 컴퓨터에 설치해야 해요. 이것은 우리가 Python을 사용해서 코딩할 때 필요한 도구예요. 설치하는 방법은 아주 쉬워요. 우리는 컴퓨터에 이 명령을 입력하기만 하면 돼요:"
      ],
      "metadata": {
        "id": "nT1ZHKvjnSbi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgl3gfkSmDIh",
        "outputId": "e020f618-3615-4553-f3de-5ac9cdfc1440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.모델 및 토크나이저 로드:**\n",
        "다음으로, 우리는 Hugging Face에서 제공하는 Vision Transformer 모델과 이 모델이 이미지를 이해할 수 있도록 도와주는 '토크나이저'를 불러와야 해요. 토크나이저는 이미지를 모델이 처리할 수 있는 형식으로 바꿔주는 역할을 해요. 이걸 위해 다음과 같은 코드를 사용하죠:\n"
      ],
      "metadata": {
        "id": "iwI3NLvVnPKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n"
      ],
      "metadata": {
        "id": "AQ2VVRqKmJR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.이미지 준비: 테스트할 이미지를 준비합니다.**\n",
        "\n",
        "\n",
        "이제, 우리가 분석할 이미지를 가져와야 해요. 이 이미지는 우리 컴퓨터에 있는 파일일 수도 있고, 인터넷에서 찾은 URL을 통해 가져올 수도 있어요. 예를 들어, 이렇게 하면 돼요:\n",
        "\n"
      ],
      "metadata": {
        "id": "2MBqlZREndo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n"
      ],
      "metadata": {
        "id": "hgM5u8t8mLqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.이미지 전처리 및 모델에 입력:**\n",
        "\n",
        "가져온 이미지를 토크나이저로 전처리하고, 이 전처리된 이미지를 모델에 입력해야 해요. 이렇게 하면 모델이 이미지를 분석할 수 있어요"
      ],
      "metadata": {
        "id": "0dS7fRXHn-Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n"
      ],
      "metadata": {
        "id": "z4-pemuXmOET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. 결과 해석:**\n",
        "마지막으로, 모델이 내놓은 결과를 해석해야 해요. 모델은 이미지가 무엇을 나타내는지 예측하고, 우리는 그 예측 결과를 볼 수 있어요\n"
      ],
      "metadata": {
        "id": "hdtNrsPUoLcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs.logits\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"이 사진을 예측해보니! :\", model.config.id2label[predicted_class_idx])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufWXqdCTmTA-",
        "outputId": "dfaf370d-9fef-4f0c-dde0-653cbe4f72b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 사진을 예측해보니! : Egyptian cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Vision Transformer (ViT)와 같은 이미지 분석 기술을 산업에 적용할 수 있는 분야는 다양합니다. 여기 몇 가지 예를 들어볼게요:\n",
        "\n",
        "의료 영상 진단: ViT는 X-레이, MRI, CT 스캔 등의 의료 영상을 분석하여 질병을 감지하고 진단하는 데 사용될 수 있습니다. 이를 통해 의료 전문가들은 더 정확하고 신속한 진단을 내릴 수 있습니다.\n",
        "\n",
        "자율 주행 차량: 자율 주행 차량은 주변 환경을 인식하고 이해하기 위해 이미지 분석 기술에 크게 의존합니다. ViT는 차량 주변의 객체를 인식하고, 도로 표지판을 해석하며, 주변 차량과 보행자의 움직임을 추적하는 데 사용될 수 있습니다.\n",
        "\n",
        "보안 및 감시: 보안 카메라 시스템에서 ViT는 사람, 차량, 기타 중요 객체를 식별하고 비정상적인 활동을 감지하는 데 사용될 수 있습니다. 이는 공공 장소, 사무실, 공장 등에서 보안과 감시를 강화하는 데 도움이 됩니다.\n",
        "\n",
        "소매 및 재고 관리: 소매업에서는 ViT를 사용하여 제품을 식별하고 분류하며, 재고를 추적하고 관리할 수 있습니다. 이를 통해 효율적인 재고 관리와 고객 경험 개선이 가능합니다.\n",
        "\n",
        "농업 및 식품 생산: ViT는 농작물의 건강 상태를 모니터링하고, 병충해를 감지하며, 작물의 성장과 수확 시기를 예측하는 데 사용될 수 있습니다. 또한, 식품 생산 과정에서 품질 관리를 위해 사용될 수도 있습니다.\n",
        "\n",
        "제조 및 품질 검사: 제조 공정에서 ViT는 제품의 결함을 감지하고 품질을 검사하는 데 사용될 수 있습니다. 이를 통해 생산 효율성을 높이고 제품 품질을 유지할 수 있습니다.\n",
        "\n",
        "환경 모니터링 및 분석: 위성 이미지와 드론 이미지 분석을 통해 환경 변화, 삼림 파괴, 도시화 진행 등을 모니터링하고 분석하는 데 ViT가 사용될 수 있습니다.\n",
        "\n",
        "이처럼 Vision Transformer는 다양한 산업 분야에서 응용될 수 있는 강력한 도구입니다. 기술의 발전에 따라 앞으로 더 많은 분야에서 그 가치가 발휘될 것으로 기대됩니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "It7CD4wCzU_-"
      }
    }
  ]
}